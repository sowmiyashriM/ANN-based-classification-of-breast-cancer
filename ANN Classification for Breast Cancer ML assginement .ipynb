{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b915ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847c15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Sowmiya/Desktop/wdbc.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e01c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['ID', 'Diagnosis', 'Mean_Radius', 'Mean_Texture', 'Mean_Perimeter', 'Mean_Area', 'Mean_Smoothness', 'Mean_Compactness', 'Mean_Concavity', 'Mean_Concave_Points', 'Mean_Symmetry', 'Mean_Fractal_Dimension', 'Radius_SE', ' Texture_SE', ' Perimeter_SE', ' Area_SE', ' Smoothness_SE', ' Compactness_SE', ' Concavity_SE', ' Concave_Points_SE', ' Symmetry_SE', ' Fractal Dimension_SE', ' Radius_Worst', ' Texture_Worst', ' Perimeter_Worst', ' Area_Worst', ' Smoothness_Worst_Worst', ' Compactness_Worst', ' Concavity_Worst', ' Concave_Points_Worst', ' Symmetry_Worst', ' Fractal Dimension_Worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abff57a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean_Radius</th>\n",
       "      <th>Mean_Texture</th>\n",
       "      <th>Mean_Perimeter</th>\n",
       "      <th>Mean_Area</th>\n",
       "      <th>Mean_Smoothness</th>\n",
       "      <th>Mean_Compactness</th>\n",
       "      <th>Mean_Concavity</th>\n",
       "      <th>Mean_Concave_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius_Worst</th>\n",
       "      <th>Texture_Worst</th>\n",
       "      <th>Perimeter_Worst</th>\n",
       "      <th>Area_Worst</th>\n",
       "      <th>Smoothness_Worst_Worst</th>\n",
       "      <th>Compactness_Worst</th>\n",
       "      <th>Concavity_Worst</th>\n",
       "      <th>Concave_Points_Worst</th>\n",
       "      <th>Symmetry_Worst</th>\n",
       "      <th>Fractal Dimension_Worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  Mean_Radius  Mean_Texture  Mean_Perimeter  Mean_Area  \\\n",
       "0    842517         M        20.57         17.77          132.90     1326.0   \n",
       "1  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "2  84348301         M        11.42         20.38           77.58      386.1   \n",
       "3  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "4    843786         M        12.45         15.70           82.57      477.1   \n",
       "5    844359         M        18.25         19.98          119.60     1040.0   \n",
       "6  84458202         M        13.71         20.83           90.20      577.9   \n",
       "7    844981         M        13.00         21.82           87.50      519.8   \n",
       "8  84501001         M        12.46         24.04           83.97      475.9   \n",
       "9    845636         M        16.02         23.24          102.70      797.8   \n",
       "\n",
       "   Mean_Smoothness  Mean_Compactness  Mean_Concavity  Mean_Concave_Points  \\\n",
       "0          0.08474           0.07864         0.08690              0.07017   \n",
       "1          0.10960           0.15990         0.19740              0.12790   \n",
       "2          0.14250           0.28390         0.24140              0.10520   \n",
       "3          0.10030           0.13280         0.19800              0.10430   \n",
       "4          0.12780           0.17000         0.15780              0.08089   \n",
       "5          0.09463           0.10900         0.11270              0.07400   \n",
       "6          0.11890           0.16450         0.09366              0.05985   \n",
       "7          0.12730           0.19320         0.18590              0.09353   \n",
       "8          0.11860           0.23960         0.22730              0.08543   \n",
       "9          0.08206           0.06669         0.03299              0.03323   \n",
       "\n",
       "   ...   Radius_Worst   Texture_Worst   Perimeter_Worst   Area_Worst  \\\n",
       "0  ...          24.99           23.41            158.80       1956.0   \n",
       "1  ...          23.57           25.53            152.50       1709.0   \n",
       "2  ...          14.91           26.50             98.87        567.7   \n",
       "3  ...          22.54           16.67            152.20       1575.0   \n",
       "4  ...          15.47           23.75            103.40        741.6   \n",
       "5  ...          22.88           27.66            153.20       1606.0   \n",
       "6  ...          17.06           28.14            110.60        897.0   \n",
       "7  ...          15.49           30.73            106.20        739.3   \n",
       "8  ...          15.09           40.68             97.65        711.4   \n",
       "9  ...          19.19           33.88            123.80       1150.0   \n",
       "\n",
       "    Smoothness_Worst_Worst   Compactness_Worst   Concavity_Worst  \\\n",
       "0                   0.1238              0.1866            0.2416   \n",
       "1                   0.1444              0.4245            0.4504   \n",
       "2                   0.2098              0.8663            0.6869   \n",
       "3                   0.1374              0.2050            0.4000   \n",
       "4                   0.1791              0.5249            0.5355   \n",
       "5                   0.1442              0.2576            0.3784   \n",
       "6                   0.1654              0.3682            0.2678   \n",
       "7                   0.1703              0.5401            0.5390   \n",
       "8                   0.1853              1.0580            1.1050   \n",
       "9                   0.1181              0.1551            0.1459   \n",
       "\n",
       "    Concave_Points_Worst   Symmetry_Worst   Fractal Dimension_Worst  \n",
       "0                0.18600           0.2750                   0.08902  \n",
       "1                0.24300           0.3613                   0.08758  \n",
       "2                0.25750           0.6638                   0.17300  \n",
       "3                0.16250           0.2364                   0.07678  \n",
       "4                0.17410           0.3985                   0.12440  \n",
       "5                0.19320           0.3063                   0.08368  \n",
       "6                0.15560           0.3196                   0.11510  \n",
       "7                0.20600           0.4378                   0.10720  \n",
       "8                0.22100           0.4366                   0.20750  \n",
       "9                0.09975           0.2948                   0.08452  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d5334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35dff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372ab222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , random_state=0,  test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f8915a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(30,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b0bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a67fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "46/46 [==============================] - 3s 5ms/step - loss: 6.3247 - accuracy: 0.3216\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.6997 - accuracy: 0.8216\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.8811\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.9009\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2884 - accuracy: 0.9075\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.9229\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2573 - accuracy: 0.9317\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.9229\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2879 - accuracy: 0.9053\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3425 - accuracy: 0.8987\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.9053\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.9075\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2530 - accuracy: 0.9317\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.9229\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8987\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2685 - accuracy: 0.9273\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.9295\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8965\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.9075\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2164 - accuracy: 0.9317\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.9207\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2685 - accuracy: 0.9185\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.9119\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.9119\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8987\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2982 - accuracy: 0.9207\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.9031\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.9295\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3236 - accuracy: 0.9207\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.9185\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.9339\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.9273\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2142 - accuracy: 0.9273\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2733 - accuracy: 0.9207\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2069 - accuracy: 0.9295\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.9207\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2621 - accuracy: 0.9251\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2664 - accuracy: 0.9207\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8943\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.9009\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8877\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8855\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2162 - accuracy: 0.9251\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.9075\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2402 - accuracy: 0.9229\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.8700\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2301 - accuracy: 0.9295\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9383\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1833 - accuracy: 0.9405\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9229\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9295\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.9163\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9229\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.9295\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.9097\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2899 - accuracy: 0.9273\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1934 - accuracy: 0.9383\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2900 - accuracy: 0.9207\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9383\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.9295\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9339\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9427\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9427\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9449\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.9185\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.9427\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9361\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9449\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9361\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9383\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8965\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9317\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.9405\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9515\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9405\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.9141\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9405\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9427\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9317\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9251\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2484 - accuracy: 0.9207\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9361\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9361\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9361\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.9449\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9317\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2546 - accuracy: 0.9075\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1372 - accuracy: 0.9449\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9427\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2720 - accuracy: 0.9119\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1434 - accuracy: 0.9471\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9317\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2441 - accuracy: 0.9207\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9449\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1981 - accuracy: 0.9317\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1861 - accuracy: 0.9471\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9515\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9317\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.9383\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19e7fa134d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0818a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bd695e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec13fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  5]\n",
      " [ 3 40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,binary_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189a6b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90173a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[0][1] + cm[1][0] +cm[1][1])\n",
    "print(\"Accuracy : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e731a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cancer (features):\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    print(features_array)\n",
    "    pred = model.predict(features_array)\n",
    "    if pred[0][0] >= 0.5:\n",
    "        return \"Malignant\"\n",
    "    else:\n",
    "        return \"Benign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a23986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.940e+01 1.818e+01 1.272e+02 1.145e+03 1.037e-01 1.442e-01 1.626e-01\n",
      "  9.464e-02 1.893e-01 5.892e-02 4.709e-01 9.951e-01 2.903e+00 5.316e+01\n",
      "  5.654e-03 2.199e-02 3.059e-02 1.499e-02 1.623e-02 1.965e-03 2.379e+01\n",
      "  2.865e+01 1.524e+02 1.628e+03 1.518e-01 3.749e-01 4.316e-01 2.252e-01\n",
      "  3.590e-01 7.787e-02]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction :  Malignant\n"
     ]
    }
   ],
   "source": [
    "new_data = [19.4,18.18,127.2,1145,0.1037,0.1442,0.1626,0.09464,0.1893,0.05892,0.4709,0.9951,2.903,53.16,0.005654,0.02199,0.03059,0.01499,0.01623,0.001965,23.79,28.65,152.4,1628,0.1518,0.3749,0.4316,0.2252,0.359,0.07787]\n",
    "predict = predict_cancer(new_data)\n",
    "print(\"Prediction : \",predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5d058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
